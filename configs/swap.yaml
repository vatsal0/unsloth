teacher_model: Qwen/Qwen2.5-7B-Instruct-Turbo
base_model: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
inference_strategy: together

n_samples: 400
max_generated_tokens: 1024
temperature: 0.8

system_prompt: |
  Respond in the following format:
  <reasoning>
  ...
  </reasoning>
  <answer>
  ...
  </answer>

context_modifier: 'swap'